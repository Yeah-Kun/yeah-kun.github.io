<!DOCTYPE HTML>
<html>
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

    

    <title>吴恩达机器学习课程——第一周笔记 | Yeah Kun blog</title>
    <meta name="author" content="Yeah Kun">
    
    <meta name="description" content="1. 单变量线性回归(Linear Regression with One Variable)1.1 模型表示$$h_\theta(x)=\theta_0+\theta_1x$$

像上述公式，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。

例子如下：
单变量线性方程，就是我">
    
    
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta property="og:title" content="吴恩达机器学习课程——第一周笔记"/>
    <meta property="og:site_name" content="Yeah Kun"/>

    
    <meta property="og:image" content="undefined"/>
    

    <link rel="icon" type="image/png" href="/favicon.png">
    <link rel="alternate" href="/atom.xml" title="Yeah Kun" type="application/atom+xml">
    <link rel="stylesheet" href="/css/lib/materialize.min.css">
    <link rel="stylesheet" href="/css/lib/font-awesome.min.css">
    <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">

    
        <link rel="stylesheet" href="/css/lib/tomorrow-night-eighties.css" type="text/css">
    
    <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
</head>


<body>
    <img src="/weixin_favicon.png" style="position: absolute; left: -9999px; opacity: 0; filter: alpha(opacity=0);">

    <nav class="light-blue accent-4">
    <div class="nav-wrapper">
        <a href="#" data-activates="main-menu" class="button-collapse">
            <i class="fa fa-navicon"></i>
        </a>
        <div class="">
            <a href="/" class="brand-logo hide-on-med-and-down">Yeah Kun</a>
            <ul class="right hide-on-med-and-down">
                
                    <li>
                        <a class="menu-home " href="/" >
                            <i class="fa fa-home "></i>
                            
                            首页
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-archive " href="/archives" >
                            <i class="fa fa-archive "></i>
                            
                            归档
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-category category-menu" href="javascript:;" data-activates="category-menu" >
                            <i class="fa fa-bookmark "></i>
                            
                            分类
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-reading " href="/reading" >
                            <i class="fa fa-book "></i>
                            
                            读书
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-about " href="/about" >
                            <i class="fa fa-user "></i>
                            
                            关于
                        </a>
                    </li>
                
                    <li>
                        <a class="menu-search modal-trigger " href="#search" >
                            <i class="fa fa-search "></i>
                            
                            搜索
                        </a>
                    </li>
                
            </ul>
            <div>
    <ul class="side-nav light-blue accent-4" id="main-menu">
        
        <li class="side-user">
            <div class="row">
                <div class="col s4 no-padding">
                    <img class="avatar-image circle responsive-img" src="http://a2.qpic.cn/psb?/V12Ltkru1ADJ5N/Jlssko4NIkOZ1gPw5*HPgUx0vSPz2P*3oTkE3K3XnXU!/b/dGkBAAAAAAAA&amp;ek=1&amp;kp=1&amp;pt=0&amp;bo=TgJOAgAAAAARFyA!&amp;tm=1493298000&amp;sce=60-3-3&amp;rf=viewer_4" alt="User Avatar">
                </div>
                <div class="info col s8 valign-wrapper no-padding">
                    <div class="valign">
                        <p class="name">叶坤</p>
                        <p class="desc">python/机器学习/心智成长</p>
                    </div>
                </div>
            </div>
        </li>
        

        
            <li class="no-padding">
                <a class="waves-effect menu-home " href="/" >
                    <i class="fa fa-home "></i>
                    
                    首页
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-archive " href="/archives" >
                    <i class="fa fa-archive "></i>
                    
                    归档
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-category category-menu" href="javascript:;" data-activates="category-menu" >
                    <i class="fa fa-bookmark "></i>
                    
                    分类
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-reading " href="/reading" >
                    <i class="fa fa-book "></i>
                    
                    读书
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-about " href="/about" >
                    <i class="fa fa-user "></i>
                    
                    关于
                </a>
            </li>
        
            <li class="no-padding">
                <a class="waves-effect menu-search modal-trigger " href="#search" >
                    <i class="fa fa-search "></i>
                    
                    搜索
                </a>
            </li>
        
    </ul>

    <ul class="side-nav light-blue accent-4" id="category-menu">
    

            

    </ul>
</div>

        </div>
    </div>
</nav>

<div id="search" class="modal search-modal">
    <div class="row">
        <div class="input-field col s12">
              <input id="search-input" type="text">
              <label for="search-input">搜索</label>
        </div>

    </div>
    <div id="search-result" class="search-result col s12">

    </div>
</div>


    <main>
        <div class="container main-container">
    <nav class="page-nav hide-on-small-only">
    <div class="nav-wrapper light-blue accent-4">
        <span class="breadcrumb">当前位置（分类目录）</span>
        
            

        

        
    </div>
</nav>

<article>
    <div class="card">
        <div class="card-content">
            

            <div class="article-title">
                
    
        <h1>吴恩达机器学习课程——第一周笔记</h1>
    


            </div>
            <time class="pink-link-context" datetime="2017-05-11T04:10:20.000Z"><a href="/2017/05/11/Machine-Learning-the-first-week/">2017-05-11</a></time>

            <span id="busuanzi_container_page_pv" class="read-times-container">
    <i class="fa fa-eye"></i>
    <span id="busuanzi_value_page_pv"></span>
</span>

            
    <div class="tags-row">
        
            <a href="/tags/机器学习/" class="chip pink lighten-1">机器学习</a>
        
    </div>


            <div class="toc pink-link-context hide-on-med-and-down">
    <ol class="section table-of-contents"><li class="section table-of-contents-item section table-of-contents-level-3"><a class="section table-of-contents-link" href="#1-单变量线性回归-Linear-Regression-with-One-Variable"><span class="section table-of-contents-text">1. 单变量线性回归(Linear Regression with One Variable)</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#1-1-模型表示"><span class="section table-of-contents-text">1.1 模型表示</span></a></li></ol></li><li class="section table-of-contents-item section table-of-contents-level-3"><a class="section table-of-contents-link" href="#2-代价函数-Cost-Function"><span class="section table-of-contents-text">2. 代价函数(Cost Function)</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#2-1公式表示"><span class="section table-of-contents-text">2.1公式表示</span></a></li><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#2-2-代价函数的直观理解①"><span class="section table-of-contents-text">2.2 代价函数的直观理解①</span></a></li><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#2-3-代价函数的直观理解②"><span class="section table-of-contents-text">2.3 代价函数的直观理解②</span></a></li></ol></li><li class="section table-of-contents-item section table-of-contents-level-3"><a class="section table-of-contents-link" href="#3-梯度下降算法-Gradient-Descent"><span class="section table-of-contents-text">3. 梯度下降算法(Gradient Descent)</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#算法思想"><span class="section table-of-contents-text">算法思想</span></a></li><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#3-1批量梯度下降-batch-gradient-descent"><span class="section table-of-contents-text">3.1批量梯度下降(batch gradient descent)</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#3-1-1-同步更新-Simultaneous-update"><span class="section table-of-contents-text">3.1.1 同步更新(Simultaneous update)</span></a></li><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#3-1-2-梯度下降算法理解"><span class="section table-of-contents-text">3.1.2 梯度下降算法理解</span></a></li><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#解决方法——乘偏导数"><span class="section table-of-contents-text">解决方法——乘偏导数</span></a></li></ol></li><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#3-1-3-线性回归的批量梯度下降"><span class="section table-of-contents-text">3.1.3 线性回归的批量梯度下降</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#批量梯度下降方程"><span class="section table-of-contents-text">批量梯度下降方程</span></a></li></ol></li><li class="section table-of-contents-item section table-of-contents-level-4"><a class="section table-of-contents-link" href="#4-线性代数基础"><span class="section table-of-contents-text">4. 线性代数基础</span></a><ol class="section table-of-contents-child"><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#4-1-矩阵的定义"><span class="section table-of-contents-text">4.1 矩阵的定义</span></a></li><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#4-2-矩阵加法-Matrix-Addition"><span class="section table-of-contents-text">4.2 矩阵加法(Matrix Addition)</span></a></li><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#4-3-矩阵乘法-Scalar-Multiplication"><span class="section table-of-contents-text">4.3 矩阵乘法(Scalar Multiplication)</span></a></li><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#4-4-矩阵的组合运算-Combination-of-Operands"><span class="section table-of-contents-text">4.4 矩阵的组合运算(Combination of Operands)</span></a></li><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#4-5-两个矩阵相乘"><span class="section table-of-contents-text">4.5 两个矩阵相乘</span></a></li><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#4-6-矩阵应用到梯度下降算法实例"><span class="section table-of-contents-text">4.6 矩阵应用到梯度下降算法实例</span></a></li><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#4-7-单位矩阵"><span class="section table-of-contents-text">4.7 单位矩阵</span></a></li><li class="section table-of-contents-item section table-of-contents-level-5"><a class="section table-of-contents-link" href="#4-8-逆矩阵"><span class="section table-of-contents-text">4.8 逆矩阵</span></a></li></ol></li></ol></li></ol>
</div>


            <div class="entry pink-link-context">
                <h3 id="1-单变量线性回归-Linear-Regression-with-One-Variable"><a href="#1-单变量线性回归-Linear-Regression-with-One-Variable" class="headerlink" title="1. 单变量线性回归(Linear Regression with One Variable)"></a>1. 单变量线性回归(Linear Regression with One Variable)</h3><h4 id="1-1-模型表示"><a href="#1-1-模型表示" class="headerlink" title="1.1 模型表示"></a>1.1 模型表示</h4><p>$$h_\theta(x)=\theta_0+\theta_1x$$</p>
<blockquote>
<p>像上述公式，因为只含有一个特征/输入变量，因此这样的问题叫作单变量线性回归问题。</p>
</blockquote>
<p>例子如下：<br><img src="http://opptp2jx7.bkt.clouddn.com/%E5%9B%9E%E5%BD%92%E5%87%BD%E6%95%B0%E5%9B%BE%E5%83%8F.png" alt="回归函数图示"></p>
<p>单变量线性方程，就是我们初中就学的一元一次函数。<br>当然啦，除了这个模型之外，我们还有很多其他的线性模型，比如指数模型、对数模型等等，除了线性模型之外，还有非线性模型，有这么多的模型，其目的就是在于更好的拟合训练集的数据，以使得预测率更高。</p>
<p>以下是对模型的具体定义：</p>
<p><img src="http://opptp2jx7.bkt.clouddn.com/%E5%9B%9E%E5%BD%92%E5%9B%BE%E7%A4%BA.png" alt="回归图示"></p>
<h3 id="2-代价函数-Cost-Function"><a href="#2-代价函数-Cost-Function" class="headerlink" title="2. 代价函数(Cost Function)"></a>2. 代价函数(Cost Function)</h3><blockquote>
<p>代价函数就是为了就是找到目的函数的最优解。</p>
</blockquote>
<p>因为在一个训练集中，有无数个模型（一元一次函数），我们需要找到最拟合这个训练集的一个函数，所以就引入了代价函数，用来找到那个最好的模型。</p>
<h4 id="2-1公式表示"><a href="#2-1公式表示" class="headerlink" title="2.1公式表示"></a>2.1公式表示</h4><p>$$J(\theta_0,\theta<em>1)=\frac{1}{2m}\sum</em>{i=1}^{m}(h_\theta(x^{(i)})-y^{(i)})^2$$</p>
<p>上述是平方误差代价函数，这也是常用到的代价函数，它通过目的函数跟各个实际值的误差平方建立新的函数。为了使这个值不受个别极端数据影响而产生巨大波动，采用类似方差再取二分之一的方式来减小个别数据的影响。<br><img src="http://opptp2jx7.bkt.clouddn.com/%E5%B9%B3%E6%96%B9%E8%AF%AF%E5%B7%AE%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%9B%BE%E7%A4%BA.png" alt="平方误差代价函数图示"></p>
<h4 id="2-2-代价函数的直观理解①"><a href="#2-2-代价函数的直观理解①" class="headerlink" title="2.2 代价函数的直观理解①"></a>2.2 代价函数的直观理解①</h4><p>最优解即为代价函数的最小值，根据以上公式多次计算可得到代价函数的图像：<br><img src="http://opptp2jx7.bkt.clouddn.com/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%9B%BE%E7%A4%BA1.1.png" alt="代价函数图示"><br>可以看到该代价函数的确有最小值，这里恰好是横坐标为1的时候。</p>
<h4 id="2-3-代价函数的直观理解②"><a href="#2-3-代价函数的直观理解②" class="headerlink" title="2.3 代价函数的直观理解②"></a>2.3 代价函数的直观理解②</h4><p>如果有更多参数，就会更为复杂，两个参数的时候就已经是三维图像了：<br><img src="http://opptp2jx7.bkt.clouddn.com/%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%9B%BE%E7%A4%BA2.png" alt="代价函数图示2"></p>
<h3 id="3-梯度下降算法-Gradient-Descent"><a href="#3-梯度下降算法-Gradient-Descent" class="headerlink" title="3. 梯度下降算法(Gradient Descent)"></a>3. 梯度下降算法(Gradient Descent)</h3><blockquote>
<p>梯度下降是一个用来求函数最小值的算法，我们将使用梯度下降算法来求出代价函数J(θ0,θ1) 的最小值。</p>
</blockquote>
<p>个人理解，代价函数是分析模型与实际训练集之间的误差，而梯度下降算法的作用，就是找出那个误差最小的代价函数。</p>
<h4 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h4><p><img src="http://opptp2jx7.bkt.clouddn.com/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3.png" alt="算法思想"></p>
<ul>
<li>从参数的某一个（组）值开始，比如从θ0=0和θ1=0开始</li>
<li>保持该（组）值持续减小，如果是一组值就要保证他们<strong>同步更新</strong>，直到找到我们希望找到的最小值</li>
</ul>
<p>我们要找到一条最快下山的路径，我们走的每一步大小就是α 。<br><img src="http://opptp2jx7.bkt.clouddn.com/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%9B%BE%E7%A4%BA1.png" alt="梯度下降图示1"></p>
<p>如果在不同的起点，最后到达的最低点也会不一样。<br><img src="http://opptp2jx7.bkt.clouddn.com/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E5%9B%BE%E7%A4%BA2.png" alt="梯度下降图示2"></p>
<h4 id="3-1批量梯度下降-batch-gradient-descent"><a href="#3-1批量梯度下降-batch-gradient-descent" class="headerlink" title="3.1批量梯度下降(batch gradient descent)"></a>3.1批量梯度下降(batch gradient descent)</h4><p>$$ repeat\  until\ convergence{\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1) (for\ j=0\ and\ j=1)} $$</p>
<ul>
<li>α：学习速率，决定我们让代价函数下降程度最大的方向迈出的步子有多大<h5 id="3-1-1-同步更新-Simultaneous-update"><a href="#3-1-1-同步更新-Simultaneous-update" class="headerlink" title="3.1.1 同步更新(Simultaneous update)"></a>3.1.1 同步更新(Simultaneous update)</h5>在梯度下降算法中，我们需要更新θ0,θ1，实现梯度下降算法的微妙之处是，在这个表达式中，如果你要更新这个等式，你需要<strong>同时</strong>更新。</li>
</ul>
<p><img src="http://opptp2jx7.bkt.clouddn.com/%E5%90%8C%E6%AD%A5%E6%9B%B4%E6%96%B0%E5%85%AC%E5%BC%8F1.png" alt="同步更新公式"></p>
<h5 id="3-1-2-梯度下降算法理解"><a href="#3-1-2-梯度下降算法理解" class="headerlink" title="3.1.2 梯度下降算法理解"></a>3.1.2 梯度下降算法理解</h5><p>如果 α 太大，那么梯度下降法可能会越过最低点，甚至可能无法收敛，下一次迭代又移动了一大步，越过一次，又越过一次，一次次越过最低点，直到你发现实际上离最低点越来越远，所以，如果 α 太大，它会导致无法收敛，甚至发散。</p>
<p><img src="http://opptp2jx7.bkt.clouddn.com/%CE%B1%E7%90%86%E8%A7%A3.png" alt="对α的理解"></p>
<h5 id="解决方法——乘偏导数"><a href="#解决方法——乘偏导数" class="headerlink" title="解决方法——乘偏导数"></a>解决方法——乘偏导数</h5><p><img src="http://opptp2jx7.bkt.clouddn.com/%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9B%B4%E8%A7%82%E5%9B%BE.png" alt="批量梯度下降直观图"></p>
<p>首先初始化我的梯度下降算法，在那个品红色的点初始化，如果<br>我更新一步梯度下降，随着我接近最低点，我的导数越来越接近零，所以，梯度下降一步后，新的导数会变小一点点。然后我想再梯度下降一步，在这个绿点，我自然会用一个稍微跟刚才在那个品红点时比，再小一点的一步，到了新的红色点，更接近全局最低点了，因此这点的导数会比在绿点时更小。所 以，我再进行一步梯度下降时，我的导数项是更小的，θ1更新的幅度就会更小。所以随着梯度下降法的运行，你移动的幅度会自动变得越来越小，直到最终移动幅度非常小，你会发现，已经收敛到局部极小值。</p>
<h4 id="3-1-3-线性回归的批量梯度下降"><a href="#3-1-3-线性回归的批量梯度下降" class="headerlink" title="3.1.3 线性回归的批量梯度下降"></a>3.1.3 线性回归的批量梯度下降</h4><p>偏导数求解推导过程</p>
<p><img src="http://opptp2jx7.bkt.clouddn.com/%E6%B1%82%E5%81%8F%E5%AF%BC%E6%95%B0%E8%BF%87%E7%A8%8B.png" alt="偏导数求解推导过程"></p>
<h5 id="批量梯度下降方程"><a href="#批量梯度下降方程" class="headerlink" title="批量梯度下降方程"></a>批量梯度下降方程</h5><p>通过上面几条公式的整合，最终得出以下公式<br><img src="http://opptp2jx7.bkt.clouddn.com/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.png" alt="线性回归方程"></p>
<h4 id="4-线性代数基础"><a href="#4-线性代数基础" class="headerlink" title="4. 线性代数基础"></a>4. 线性代数基础</h4><p>个人现在认为，线性代数的作用主要是为了方便操作训练集。</p>
<h5 id="4-1-矩阵的定义"><a href="#4-1-矩阵的定义" class="headerlink" title="4.1 矩阵的定义"></a>4.1 矩阵的定义</h5><p>横为行，竖为列，表示方法一般是$ R^{m*n} $<br><img src="http://opptp2jx7.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E7%9A%84%E5%AE%9A%E4%B9%89.png" alt="矩阵的定义"></p>
<p>寻找某个矩阵元素<br><img src="http://opptp2jx7.bkt.clouddn.com/%E6%9F%90%E4%B8%AA%E7%9F%A9%E9%98%B5%E5%85%83%E7%B4%A0.png" alt="某个矩阵元素"></p>
<h5 id="4-2-矩阵加法-Matrix-Addition"><a href="#4-2-矩阵加法-Matrix-Addition" class="headerlink" title="4.2 矩阵加法(Matrix Addition)"></a>4.2 矩阵加法(Matrix Addition)</h5><p>同一个位置的矩阵元素相加，得到新的矩阵<br><img src="http://opptp2jx7.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E5%8A%A0%E6%B3%95.png" alt="矩阵加法"></p>
<h5 id="4-3-矩阵乘法-Scalar-Multiplication"><a href="#4-3-矩阵乘法-Scalar-Multiplication" class="headerlink" title="4.3 矩阵乘法(Scalar Multiplication)"></a>4.3 矩阵乘法(Scalar Multiplication)</h5><p>将值与矩阵每个元素相乘，得到新的矩阵<br><img src="http://opptp2jx7.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E4%B9%98%E9%99%A4%E6%B3%95.png" alt="矩阵乘法"></p>
<h5 id="4-4-矩阵的组合运算-Combination-of-Operands"><a href="#4-4-矩阵的组合运算-Combination-of-Operands" class="headerlink" title="4.4 矩阵的组合运算(Combination of Operands)"></a>4.4 矩阵的组合运算(Combination of Operands)</h5><p>将矩阵加减法和乘除法结合起来，道理都一样<br><img src="http://opptp2jx7.bkt.clouddn.com/%E7%9F%A9%E9%98%B5%E7%BB%84%E5%90%88%E8%BF%90%E7%AE%97.png" alt="矩阵的组合运算"></p>
<h5 id="4-5-两个矩阵相乘"><a href="#4-5-两个矩阵相乘" class="headerlink" title="4.5 两个矩阵相乘"></a>4.5 两个矩阵相乘</h5><p>A矩阵的行 乘 B矩阵的列 得到新矩阵 y 。<br><img src="http://opptp2jx7.bkt.clouddn.com/%E4%B8%A4%E4%B8%AA%E7%9F%A9%E9%98%B5%E7%9B%B8%E4%B9%98.png" alt="两个矩阵相乘1"></p>
<p><img src="http://opptp2jx7.bkt.clouddn.com/%E4%B8%A4%E4%B8%AA%E7%9F%A9%E9%98%B5%E7%9B%B8%E4%B9%982.png" alt="两个矩阵相乘2"></p>
<h5 id="4-6-矩阵应用到梯度下降算法实例"><a href="#4-6-矩阵应用到梯度下降算法实例" class="headerlink" title="4.6 矩阵应用到梯度下降算法实例"></a>4.6 矩阵应用到梯度下降算法实例</h5><p>把训练集做成一个矩阵，把线性回归方程做成另外一个矩阵，将两个矩阵相乘，最后就能得出一个新的矩阵。<br><img src="http://opptp2jx7.bkt.clouddn.com/%E5%BA%94%E7%94%A8%E5%88%B0%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E4%BE%8B.png" alt="矩阵应用到梯度下降算法实例图示"></p>
<h5 id="4-7-单位矩阵"><a href="#4-7-单位矩阵" class="headerlink" title="4.7 单位矩阵"></a>4.7 单位矩阵</h5><blockquote>
<p>在矩阵的乘法中，有一种矩阵起着特殊的作用，如同数的乘法中的1,这种矩阵被称为单位矩阵．它是个方阵，从左上角到右下角的对角线（称为主对角线）上的元素均为1。除此以外全都为0。</p>
</blockquote>
<p><img src="http://opptp2jx7.bkt.clouddn.com/%E5%8D%95%E4%BD%8D%E7%9F%A9%E9%98%B5.png" alt="单位矩阵"></p>
<p>除0矩阵外，任何矩阵乘单位矩阵都等于它本身。</p>
<p><img src="http://opptp2jx7.bkt.clouddn.com/%E5%8D%95%E4%BD%8D%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97.png" alt="单位矩阵运算"></p>
<h5 id="4-8-逆矩阵"><a href="#4-8-逆矩阵" class="headerlink" title="4.8 逆矩阵"></a>4.8 逆矩阵</h5><p><img src="http://opptp2jx7.bkt.clouddn.com/%E9%80%86%E7%9F%A9%E9%98%B5%E7%9A%84%E5%AE%9A%E4%B9%89.png" alt="定义"></p>
<p>用octave求得逆矩阵：pinv()函数</p>
<p><img src="http://opptp2jx7.bkt.clouddn.com/octave%E6%B1%82%E9%80%86%E7%9F%A9%E9%98%B5.png" alt="octave求得逆矩阵"></p>

                
<p class="pink-link-context">
    <a href="/2017/05/06/嵌入式Linux课/" rel="next" title="嵌入式Linux课">
    上一篇：嵌入式Linux课
  </a>
</p>




            </div>
			
        </div>
    </div>
</article>






</div>

        <div class="fixed-action-btn float-sitemap">
    <a class="btn-floating btn-large pink">
      <i class="fa fa-caret-square-o-up"></i>
    </a>
    <ul>
      <li><a class="btn-return-top btn-floating waves-effect green" title="回到顶部"><i class="fa fa-arrow-circle-o-up"></i></a></li>
      <li><a class="btn-floating waves-effect button-collapse yellow darken-1"  data-activates="main-menu" title="menu"><i class="fa fa-navicon"></i></a></li>
    </ul>
  </div>

    </main>
    <footer class="page-footer light-blue accent-4 darken-1">
    
    <div class="container">
        <div class="row">
            
            <div class="social-group col m4 s12">
                <h5 class="white-text">社交</h5>
                
                    <a class="social-link" href="http://weibo.com/2660835460/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo&amp;is_all=1" target="_blank">
                        <i class="fa fa-2x fa-weibo"></i>
                    </a>
                
                    <a class="social-link" href="https://github.com/Yeah-Kun" target="_blank">
                        <i class="fa fa-2x fa-github"></i>
                    </a>
                
                    <a class="social-link" href="/atom.xml" target="_blank">
                        <i class="fa fa-2x fa-rss"></i>
                    </a>
                
                <div class="site-visitors-container white-text">
                    <span>
                        <i class="fa fa-user"></i>
                        <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
                    </span>
                    <span>&nbsp;|&nbsp;</span>
                    <span>
                        <i class="fa fa-eye"></i>
                        <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
                    </span>
                </div>
            </div>
            

            
            <div class="col m8 s12">
                <h5 class="white-text">友情链接</h5>
                
                    <a class="social-link" href="http://raytaylorlin.com/" target="_blank">raytaylorism主题作者的技术博客</a>
                
                    <a class="social-link" href="https://github.com/raytaylorlin" target="_blank">Github地址（测试友情链接）</a>
                
            </div>
            
        </div>
    </div>
    

    <div class="footer-copyright pink-link-context">
        <div class="container">
            © 2017 yeah-kun.com, All rights reserved.
            <p class="right" style="margin-top: 0;">本博客由 <a href="https://hexo.io">Hexo</a> 强力驱动 | 主题 <a href="https://github.com/raytaylorlin/hexo-theme-raytaylorism">raytaylorism</a></p>
        </div>
    </div>
</footer>


    <noscript>
    <div class="noscript">
        <p class="center-align">当前网速较慢或者你使用的浏览器不支持博客特定功能，请尝试刷新或换用Chrome、Firefox等现代浏览器</p>
    </div>
</noscript>
<div class="noscript">
    <p class="center-align">当前网速较慢或者你使用的浏览器不支持博客特定功能，请尝试刷新或换用Chrome、Firefox等现代浏览器</p>
</div>


<script src="/js/jquery.min.js"></script>
<script src="/js/materialize.min.js"></script>
<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<script>
    (function($) {
        $(document).ready(function() {
            // 隐藏禁用javascript（针对微信内置浏览器）的提示
            $('.noscript').hide();

            // 图片缩放效果
            var $imgs = $('img').not('.slider-image').not('.avatar-image').not('.carousel-image').not('.card-cover-image').not('.qrcode');

            // 给图片加上点击放大效果（materialbox插件）
            $imgs.addClass('materialboxed').each(function(i, el) {
                $(this).attr('data-caption', $(this).attr('alt') || ' ');
            }).materialbox();

            // 优化表格的显示
            $('table').each(function() {
                var $table = $(this);
                // 除去多行代码的情况
                if ($table.find('pre').length == 0) {
                    $table.addClass('responsive-table striped bordered');
                }
            });

            // 首页幻灯片
            $('.slider').slider({indicators: true, full_width: true, interval: 8000});

            $(".button-collapse").sideNav();
            $(".category-menu").sideNav();

            // 针对gallery post
            $('.carousel').carousel({full_width: true});
            $('.carousel-control.prev').click(function() {
                $('.carousel').carousel('prev');
            });
            $('.carousel-control.next').click(function() {
                $('.carousel').carousel('next');
            });

            // 文章目录
            $('article').not('.simple-article').find('h1').add('h2').add('h3').add('h4').add('h5').add('h6').scrollSpy();

            // 目录随屏幕滚动（防止目录过长越过footer）
            var $toc = $('.toc');
            var scrollTargetTop = 0;
            $(window).scroll(function() {
                var $activeLink = $toc.find('a.active.section');
                if ($(window).scrollTop() < 100) {
                    scrollTargetTop = 0;
                } else {
                    if ($activeLink[0]) {
                        scrollTargetTop = $activeLink.offset().top - $toc.offset().top;
                    }
                }
                $toc.css('top', '-' + scrollTargetTop + 'px');
            });

            // 修正文章目录的left-border颜色
            var color = $('.table-of-contents-text').css('color');
            $('.table-of-contents-link').css('border-left-color', color);

            // 针对移动端做的优化：FAB按钮点击一下收回
            if (/Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent)) {
                $('.fixed-action-btn').addClass('click-to-toggle');
            }
            // 回到顶部
            $('.btn-return-top').click(function() {
                $('body, html').animate({
                    scrollTop: 0
                }, 500);
            });

            // 重置读书页面的Tab标签页的颜色
            $('li.tab a').hover(function() {
                $(this).toggleClass('text-lighten-4');
            });
            $('.indicator').addClass('pink lighten-2');

            
            // 添加new标签
            $('.menu-reading, .menu-about').append('<span class="new badge pink"></span>');
            

            // 搜索功能
            $('.modal-trigger').leanModal({
                // 打开搜索框时自动聚焦
                ready: function() {
                    if ($('#search').is(":visible")) {
                        $('#search-input').focus();
                    }
                }
            });
            var searchXml = "";
            if (searchXml.length == 0) {
             	searchXml = "search.xml";
            }
            var searchPath = "/" + searchXml;
            initSearch(searchPath, 'search-input', 'search-result');
        });

        // 初始化搜索与匹配函数
        var initSearch = function(path, search_id, content_id) {
            'use strict';
            $.ajax({
                url: path,
                dataType: "xml",
                success: function(xmlResponse) {
                    // get the contents from search data
                    var datas = $("entry", xmlResponse).map(function() {
                        return {
                            title: $("title", this).text(),
                            content: $("content", this).text(),
                            url: $("url", this).text()
                        };
                    }).get();
                    var $input = document.getElementById(search_id);
                    var $resultContent = document.getElementById(content_id);
                    $input.addEventListener('input', function() {
                        var str = '<ul class=\"search-result-list\">';
                        var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                        $resultContent.innerHTML = "";
                        if (this.value.trim().length <= 0) {
                            return;
                        }
                        // perform local searching
                        datas.forEach(function(data) {
                            var isMatch = true;
                            var content_index = [];
                            var data_title = data.title.trim().toLowerCase();
                            var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                            var data_url = data.url;
                            var index_title = -1;
                            var index_content = -1;
                            var first_occur = -1;
                            // only match artiles with not empty titles and contents
                            if (data_title != '' && data_content != '') {
                                keywords.forEach(function(keyword, i) {
                                    index_title = data_title.indexOf(keyword);
                                    index_content = data_content.indexOf(keyword);
                                    if (index_title < 0 && index_content < 0) {
                                        isMatch = false;
                                    } else {
                                        if (index_content < 0) {
                                            index_content = 0;
                                        }
                                        if (i == 0) {
                                            first_occur = index_content;
                                        }
                                    }
                                });
                            }
                            // show search results
                            if (isMatch) {
                                keywords.forEach(function(keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    data_title = data_title.replace(regS, "<span class=\"search-keyword pink lighten-2\">" + keyword + "</span>");
                                });

                                str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                                var content = data.content.trim().replace(/<[^>]+>/g, "");
                                if (first_occur >= 0) {
                                    // cut out 100 characters
                                    var start = first_occur - 20;
                                    var end = first_occur + 80;
                                    if (start < 0) {
                                        start = 0;
                                    }
                                    if (start == 0) {
                                        end = 100;
                                    }
                                    if (end > content.length) {
                                        end = content.length;
                                    }
                                    var match_content = content.substring(start, end);
                                    // highlight all keywords
                                    keywords.forEach(function(keyword) {
                                        var regS = new RegExp(keyword, "gi");
                                        match_content = match_content.replace(regS, "<span class=\"search-keyword pink lighten-2\">" + keyword + "</span>");
                                    });

                                    str += "<p class=\"search-result\">..." + match_content + "...</p>"
                                }
                                str += "</li>";
                            }
                        });
                        str += "</ul>";
                        $resultContent.innerHTML = str;
                    });
                }
            });
        }
    })(jQuery);
</script>


<script src="/js/prettify.js"></script>
<script type="text/javascript">
    $(document).ready(function() {
        $("pre").addClass("prettyprint");
        prettyPrint();
    });
</script>


<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-98292524-1', 'auto');
    ga('send', 'pageview');

</script>





<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/javascript" async
  src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>



</body>
</html>
